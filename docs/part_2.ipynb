{"cells":[{"cell_type":"markdown","source":["# Part 2"],"metadata":{"collapsed":false,"pycharm":{"name":"#%% md\n"},"id":"ZpVZVbZA0R0y"}},{"cell_type":"markdown","source":["## Tutorial Part 2: Computer Vision with TransferLearning"],"metadata":{"collapsed":false,"id":"y9_N1ZdO0R0z"}},{"cell_type":"markdown","source":["**Transfer Learning** - storing knowledge gained while solving one problem and applying it to a different but related problem.\n","> [More information](https://en.wikipedia.org/wiki/Transfer_learning)"],"metadata":{"collapsed":false,"id":"gINCcp0L0R00"}},{"cell_type":"markdown","source":["TensorFlow has good selection of pre-trained models that can be imported right in TensorFlow model. It is called [*TensorFlow Hub*](https://tfhub.dev).\n","As a compliment to main framework Google has published also additional package called [*TensorFlow Datasets*](https://www.tensorflow.org/datasets/catalog/overview#all_datasets) which has collection of the most popular datasets.\n","\n","In this part of tutorial we will use [*The Standford Dogs dataset*](https://www.tensorflow.org/datasets/catalog/stanford_dogs) imported through TensorFlow datasets."],"metadata":{"collapsed":false,"id":"w8byuxFN0R00"}},{"cell_type":"markdown","source":["## Check if gpu is available and TF version"],"metadata":{"collapsed":false,"id":"C7JUkaro0R00"}},{"cell_type":"code","execution_count":82,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'2.9.2'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":82}],"source":["import tensorflow as tf\n","tf.__version__"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"Ut_yHMRK0R01","executionInfo":{"status":"ok","timestamp":1666630387045,"user_tz":-180,"elapsed":341,"user":{"displayName":"V Lohmanova","userId":"03171650844612985685"}},"outputId":"cfa98ed6-a594-45bc-baba-843963992371","colab":{"base_uri":"https://localhost:8080/","height":35}}},{"cell_type":"code","execution_count":83,"outputs":[{"output_type":"stream","name":"stdout","text":["Mon Oct 24 16:53:07 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   72C    P0    30W /  70W |  14632MiB / 15109MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","+-----------------------------------------------------------------------------+\n"]}],"source":["!nvidia-smi"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"KDtYUJCi0R02","outputId":"ae3a5c16-1e8a-4551-86b5-642f07eda46d","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1666630388024,"user_tz":-180,"elapsed":291,"user":{"displayName":"V Lohmanova","userId":"03171650844612985685"}}}},{"cell_type":"markdown","source":["## Get data"],"metadata":{"collapsed":false,"id":"U6QX3bCi0R02"}},{"cell_type":"code","execution_count":84,"outputs":[],"source":["import tensorflow_datasets as tfds"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"gNhcL3W40R02","executionInfo":{"status":"ok","timestamp":1666630388968,"user_tz":-180,"elapsed":2,"user":{"displayName":"V Lohmanova","userId":"03171650844612985685"}}}},{"cell_type":"code","execution_count":85,"outputs":[],"source":["(train_data, test_data), ds_info = tfds.load(name='stanford_dogs',\n","                                             split=['train', 'test'],\n","                                             shuffle_files=True,\n","                                             as_supervised=True,\n","                                             with_info=True,\n","                                             batch_size=32)"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"bVRi7Goe0R03","executionInfo":{"status":"ok","timestamp":1666630389723,"user_tz":-180,"elapsed":1,"user":{"displayName":"V Lohmanova","userId":"03171650844612985685"}}}},{"cell_type":"code","execution_count":86,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tfds.core.DatasetInfo(\n","    name='stanford_dogs',\n","    full_name='stanford_dogs/0.2.0',\n","    description=\"\"\"\n","    The Stanford Dogs dataset contains images of 120 breeds of dogs from around\n","    the world. This dataset has been built using images and annotation from\n","    ImageNet for the task of fine-grained image categorization. There are\n","    20,580 images, out of which 12,000 are used for training and 8580 for\n","    testing. Class labels and bounding box annotations are provided\n","    for all the 12,000 images.\n","    \"\"\",\n","    homepage='http://vision.stanford.edu/aditya86/ImageNetDogs/main.html',\n","    data_path='~/tensorflow_datasets/stanford_dogs/0.2.0',\n","    file_format=tfrecord,\n","    download_size=778.12 MiB,\n","    dataset_size=744.72 MiB,\n","    features=FeaturesDict({\n","        'image': Image(shape=(None, None, 3), dtype=tf.uint8),\n","        'image/filename': Text(shape=(), dtype=tf.string),\n","        'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=120),\n","        'objects': Sequence({\n","            'bbox': BBoxFeature(shape=(4,), dtype=tf.float32),\n","        }),\n","    }),\n","    supervised_keys=('image', 'label'),\n","    disable_shuffling=False,\n","    splits={\n","        'test': <SplitInfo num_examples=8580, num_shards=4>,\n","        'train': <SplitInfo num_examples=12000, num_shards=4>,\n","    },\n","    citation=\"\"\"@inproceedings{KhoslaYaoJayadevaprakashFeiFei_FGVC2011,\n","    author = \"Aditya Khosla and Nityananda Jayadevaprakash and Bangpeng Yao and\n","              Li Fei-Fei\",\n","    title = \"Novel Dataset for Fine-Grained Image Categorization\",\n","    booktitle = \"First Workshop on Fine-Grained Visual Categorization,\n","                 IEEE Conference on Computer Vision and Pattern Recognition\",\n","    year = \"2011\",\n","    month = \"June\",\n","    address = \"Colorado Springs, CO\",\n","    }\n","    @inproceedings{imagenet_cvpr09,\n","            AUTHOR = {Deng, J. and Dong, W. and Socher, R. and Li, L.-J. and\n","                      Li, K. and Fei-Fei, L.},\n","            TITLE = {{ImageNet: A Large-Scale Hierarchical Image Database}},\n","            BOOKTITLE = {CVPR09},\n","            YEAR = {2009},\n","            BIBSOURCE = \"http://www.image-net.org/papers/imagenet_cvpr09.bib\"}\"\"\",\n",")"]},"metadata":{},"execution_count":86}],"source":["ds_info"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"AVQPXIWY0R03","outputId":"a95f9679-a888-4b8d-d2a8-e4481d7c5845","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1666630389950,"user_tz":-180,"elapsed":2,"user":{"displayName":"V Lohmanova","userId":"03171650844612985685"}}}},{"cell_type":"code","execution_count":87,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(<PrefetchDataset element_spec=(TensorSpec(shape=(None, None, None, 3), dtype=tf.uint8, name=None), TensorSpec(shape=(None,), dtype=tf.int64, name=None))>,\n"," <PrefetchDataset element_spec=(TensorSpec(shape=(None, None, None, 3), dtype=tf.uint8, name=None), TensorSpec(shape=(None,), dtype=tf.int64, name=None))>)"]},"metadata":{},"execution_count":87}],"source":["train_data, test_data"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"EJbo_DgA0R03","outputId":"90dfc698-8f26-4d9f-e21d-d564516edafc","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1666630391663,"user_tz":-180,"elapsed":3,"user":{"displayName":"V Lohmanova","userId":"03171650844612985685"}}}},{"cell_type":"markdown","source":["## Prepare data"],"metadata":{"collapsed":false,"pycharm":{"name":"#%% md\n"},"id":"bEH8gZ7a0R03"}},{"cell_type":"markdown","source":["### Batch and prefetch"],"metadata":{"collapsed":false,"pycharm":{"name":"#%% md\n"},"id":"ibUf4Kni0R04"}},{"cell_type":"code","execution_count":88,"outputs":[],"source":["import tensorflow as tf"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"6GkPogF40R04","executionInfo":{"status":"ok","timestamp":1666630394403,"user_tz":-180,"elapsed":4,"user":{"displayName":"V Lohmanova","userId":"03171650844612985685"}}}},{"cell_type":"code","execution_count":89,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(<PrefetchDataset element_spec=(TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.int64, name=None))>,\n"," <PrefetchDataset element_spec=(TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.int64, name=None))>)"]},"metadata":{},"execution_count":89}],"source":["# train_data = train_data.batch(32).prefetch(tf.data.AUTOTUNE)\n","# test_data = test_data.batch(32).prefetch(tf.data.AUTOTUNE)\n","# TFDS already batched dataset for us\n","train_data = train_data.map(lambda image, label: (tf.image.resize(image, (224, 224)), label)).prefetch(tf.data.AUTOTUNE)\n","test_data = test_data.map(lambda image, label: (tf.image.resize(image, (224, 224)), label)).prefetch(tf.data.AUTOTUNE)\n","len(train_data), len(test_data)"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"r2W17s-E0R04","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1666630394403,"user_tz":-180,"elapsed":3,"user":{"displayName":"V Lohmanova","userId":"03171650844612985685"}},"outputId":"af5f484e-d54e-4afd-93d9-a8a997f7ff19"}},{"cell_type":"markdown","source":["**Note:**\n","\n","* **Batch size** - the number of samples that are passed to the network at once.\n","![Training with large minibatches is bad for your heath](https://github.com/fulcrum101/Problemcon_hackathon_TensorFlow/blob/master/docs/assets/tweet_2.png?raw=1)\n","[Revisiting Small Batch Training for deep Neural Networks paper](https://arxiv.org/abs/1804.07612)\n","* **Prefetching** overlaps the preprocessing and model execution of a training step.\n","> On the step `s`, the input pipeline is reading the data for step `s+1`.\n",">\n","> `tf.data.AUTOTUNE` tunes value dynamically at runtime.\n","\n","[More information](https://www.tensorflow.org/guide/data_performance)"],"metadata":{"collapsed":false,"pycharm":{"name":"#%% md\n"},"id":"ZOF9JkR80R05"}},{"cell_type":"markdown","source":["### Data Augmentation"],"metadata":{"collapsed":false,"pycharm":{"name":"#%% md\n"},"id":"qQA8RC2s0R05"}},{"cell_type":"markdown","source":["*Data Augmentation* is important concept against *overfitting* problem.\n","* **Data Augmentation** - a technique to increase the diversity of your training set by applying random (but realistic) transformations, such as image rotation.\n","> [More Information](https://www.tensorflow.org/tutorials/images/data_augmentation)\n","* **Overfiting** -  concept in data science, which occurs when a statistical model fit exactly against its training data\n","> [More Information](https://www.ibm.com/cloud/learn/overfitting)"],"metadata":{"collapsed":false,"pycharm":{"name":"#%% md\n"},"id":"yfsUu8N80R05"}},{"cell_type":"code","execution_count":90,"outputs":[],"source":["# Build data augmentation layer\n","# Note: in TensorFlow models can be used as layers\n","from tensorflow.keras import layers\n","\n","data_augmentation = tf.keras.models.Sequential([\n","    layers.RandomHeight(0.2), # https://www.tensorflow.org/api_docs/python/tf/keras/layers/RandomHeight\n","    layers.RandomWidth(0.2), # https://www.tensorflow.org/api_docs/python/tf/keras/layers/RandomWidth\n","    layers.RandomFlip(), # https://www.tensorflow.org/api_docs/python/tf/keras/layers/RandomFlip\n","    layers.RandomZoom(0.2), # https://www.tensorflow.org/api_docs/python/tf/keras/layers/RandomZoom\n","    layers.RandomRotation(0.2) # https://www.tensorflow.org/api_docs/python/tf/keras/layers/RandomRotation\n","], name='data_augmentation')"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"X0u3NLFW0R06","executionInfo":{"status":"ok","timestamp":1666630396683,"user_tz":-180,"elapsed":243,"user":{"displayName":"V Lohmanova","userId":"03171650844612985685"}}}},{"cell_type":"markdown","source":["## Build model"],"metadata":{"collapsed":false,"pycharm":{"name":"#%% md\n"},"id":"aD2CntMF0R06"}},{"cell_type":"markdown","source":["### Get pretrained model"],"metadata":{"collapsed":false,"pycharm":{"name":"#%% md\n"},"id":"CTsr8Cjn0R06"}},{"cell_type":"markdown","source":["Links:\n","- [Documentation](https://www.tensorflow.org/api_docs/python/tf/keras/applications/efficientnet/EfficientNetB0)\n","\n","- [TF Hub](https://tfhub.dev/google/collections/efficientnet/1)"],"metadata":{"collapsed":false,"id":"zxeBmRwM0R07"}},{"cell_type":"code","execution_count":91,"outputs":[],"source":["base_model = tf.keras.applications.EfficientNetB0(include_top=False)\n","base_model.trainable = False # Freeze model's weigth"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"JalZXcJr0R07","executionInfo":{"status":"ok","timestamp":1666630400053,"user_tz":-180,"elapsed":1616,"user":{"displayName":"V Lohmanova","userId":"03171650844612985685"}}}},{"cell_type":"markdown","source":["### Callbacks\n","* `ModelCheckpoint` - saves model or model weights at some frequency.\n","> [More information](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/ModelCheckpoint)\n","* `EarlyStopping` - stops training when a monitored metric has stopped improving.\n","> [More information](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/EarlyStopping)"],"metadata":{"collapsed":false,"pycharm":{"name":"#%% md\n"},"id":"uRd2N2qP0R07"}},{"cell_type":"code","execution_count":92,"outputs":[],"source":["checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath='model_checkpoints/checkpoint.ckpt',\n","                                                         save_weights_only=True,\n","                                                         save_best_only=True,\n","                                                         save_freq='epoch',\n","                                                         verbose=1)"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"1MWyR9NN0R07","executionInfo":{"status":"ok","timestamp":1666630402089,"user_tz":-180,"elapsed":2,"user":{"displayName":"V Lohmanova","userId":"03171650844612985685"}}}},{"cell_type":"code","execution_count":93,"outputs":[],"source":["early_stopping_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n","                                                           verbose=1,\n","                                                           restore_best_weights=True,\n","                                                           patience=5)"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"-Pn4SvOr0R07","executionInfo":{"status":"ok","timestamp":1666630402400,"user_tz":-180,"elapsed":2,"user":{"displayName":"V Lohmanova","userId":"03171650844612985685"}}}},{"cell_type":"markdown","source":["### Create a model with Functional API"],"metadata":{"collapsed":false,"id":"wg3UHIY80R07"}},{"cell_type":"code","execution_count":94,"outputs":[],"source":["inputs = tf.keras.layers.Input(shape=(224, 224, 3), name='input_layer')\n","x = data_augmentation(inputs)\n","x = base_model(x, training=False)\n","x = tf.keras.layers.GlobalAveragePooling2D(name='global_average_pooling_layer')(x)\n","outputs = tf.keras.layers.Dense(120, activation='softmax', name='output_layer')(x)"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"7M3faQR60R08","executionInfo":{"status":"ok","timestamp":1666630404680,"user_tz":-180,"elapsed":708,"user":{"displayName":"V Lohmanova","userId":"03171650844612985685"}}}},{"cell_type":"code","execution_count":95,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"cv_model\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_layer (InputLayer)    [(None, 224, 224, 3)]     0         \n","                                                                 \n"," data_augmentation (Sequenti  (None, 224, 224, 3)      0         \n"," al)                                                             \n","                                                                 \n"," efficientnetb0 (Functional)  (None, None, None, 1280)  4049571  \n","                                                                 \n"," global_average_pooling_laye  (None, 1280)             0         \n"," r (GlobalAveragePooling2D)                                      \n","                                                                 \n"," output_layer (Dense)        (None, 120)               153720    \n","                                                                 \n","=================================================================\n","Total params: 4,203,291\n","Trainable params: 153,720\n","Non-trainable params: 4,049,571\n","_________________________________________________________________\n"]}],"source":["model = tf.keras.models.Model(inputs, outputs, name='cv_model')\n","model.summary()"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"vGjvE0tH0R08","outputId":"278dba2d-ca34-4b4e-eadd-0bbd9ea913be","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1666630404680,"user_tz":-180,"elapsed":9,"user":{"displayName":"V Lohmanova","userId":"03171650844612985685"}}}},{"cell_type":"code","execution_count":96,"outputs":[],"source":["model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n","              optimizer=tf.keras.optimizers.Adam(),\n","              metrics=['accuracy'])"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"f_WsYMdB0R08","executionInfo":{"status":"ok","timestamp":1666630406004,"user_tz":-180,"elapsed":1,"user":{"displayName":"V Lohmanova","userId":"03171650844612985685"}}}},{"cell_type":"code","execution_count":97,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","375/375 [==============================] - ETA: 0s - loss: 3.8025 - accuracy: 0.1755\n","Epoch 1: val_loss improved from inf to 2.24280, saving model to model_checkpoints/checkpoint.ckpt\n","375/375 [==============================] - 89s 221ms/step - loss: 3.8025 - accuracy: 0.1755 - val_loss: 2.2428 - val_accuracy: 0.4900\n","Epoch 2/100\n","375/375 [==============================] - ETA: 0s - loss: 3.0469 - accuracy: 0.3007\n","Epoch 2: val_loss improved from 2.24280 to 1.78028, saving model to model_checkpoints/checkpoint.ckpt\n","375/375 [==============================] - 78s 206ms/step - loss: 3.0469 - accuracy: 0.3007 - val_loss: 1.7803 - val_accuracy: 0.5590\n","Epoch 3/100\n","375/375 [==============================] - ETA: 0s - loss: 2.8219 - accuracy: 0.3380\n","Epoch 3: val_loss improved from 1.78028 to 1.69082, saving model to model_checkpoints/checkpoint.ckpt\n","375/375 [==============================] - 76s 201ms/step - loss: 2.8219 - accuracy: 0.3380 - val_loss: 1.6908 - val_accuracy: 0.5696\n","Epoch 4/100\n","375/375 [==============================] - ETA: 0s - loss: 2.6891 - accuracy: 0.3624\n","Epoch 4: val_loss improved from 1.69082 to 1.65986, saving model to model_checkpoints/checkpoint.ckpt\n","375/375 [==============================] - 76s 201ms/step - loss: 2.6891 - accuracy: 0.3624 - val_loss: 1.6599 - val_accuracy: 0.5625\n","Epoch 5/100\n","375/375 [==============================] - ETA: 0s - loss: 2.6073 - accuracy: 0.3811\n","Epoch 5: val_loss improved from 1.65986 to 1.56977, saving model to model_checkpoints/checkpoint.ckpt\n","375/375 [==============================] - 74s 196ms/step - loss: 2.6073 - accuracy: 0.3811 - val_loss: 1.5698 - val_accuracy: 0.5784\n","Epoch 6/100\n","375/375 [==============================] - ETA: 0s - loss: 2.5088 - accuracy: 0.4027\n","Epoch 6: val_loss did not improve from 1.56977\n","375/375 [==============================] - 70s 186ms/step - loss: 2.5088 - accuracy: 0.4027 - val_loss: 1.5869 - val_accuracy: 0.5749\n","Epoch 7/100\n","375/375 [==============================] - ETA: 0s - loss: 2.4902 - accuracy: 0.4025\n","Epoch 7: val_loss improved from 1.56977 to 1.55353, saving model to model_checkpoints/checkpoint.ckpt\n","375/375 [==============================] - 69s 184ms/step - loss: 2.4902 - accuracy: 0.4025 - val_loss: 1.5535 - val_accuracy: 0.5784\n","Epoch 8/100\n","375/375 [==============================] - ETA: 0s - loss: 2.3965 - accuracy: 0.4259\n","Epoch 8: val_loss improved from 1.55353 to 1.55162, saving model to model_checkpoints/checkpoint.ckpt\n","375/375 [==============================] - 69s 182ms/step - loss: 2.3965 - accuracy: 0.4259 - val_loss: 1.5516 - val_accuracy: 0.5831\n","Epoch 9/100\n","375/375 [==============================] - ETA: 0s - loss: 2.3380 - accuracy: 0.4368\n","Epoch 9: val_loss improved from 1.55162 to 1.50542, saving model to model_checkpoints/checkpoint.ckpt\n","375/375 [==============================] - 69s 184ms/step - loss: 2.3380 - accuracy: 0.4368 - val_loss: 1.5054 - val_accuracy: 0.6061\n","Epoch 10/100\n","375/375 [==============================] - ETA: 0s - loss: 2.4117 - accuracy: 0.4186\n","Epoch 10: val_loss did not improve from 1.50542\n","375/375 [==============================] - 67s 179ms/step - loss: 2.4117 - accuracy: 0.4186 - val_loss: 1.5490 - val_accuracy: 0.5831\n","Epoch 11/100\n","375/375 [==============================] - ETA: 0s - loss: 2.2914 - accuracy: 0.4478\n","Epoch 11: val_loss did not improve from 1.50542\n","375/375 [==============================] - 65s 173ms/step - loss: 2.2914 - accuracy: 0.4478 - val_loss: 1.5647 - val_accuracy: 0.5896\n","Epoch 12/100\n","375/375 [==============================] - ETA: 0s - loss: 2.2642 - accuracy: 0.4505\n","Epoch 12: val_loss did not improve from 1.50542\n","375/375 [==============================] - 64s 171ms/step - loss: 2.2642 - accuracy: 0.4505 - val_loss: 1.5737 - val_accuracy: 0.5837\n","Epoch 13/100\n","375/375 [==============================] - ETA: 0s - loss: 2.2836 - accuracy: 0.4470\n","Epoch 13: val_loss did not improve from 1.50542\n","375/375 [==============================] - 65s 172ms/step - loss: 2.2836 - accuracy: 0.4470 - val_loss: 1.5595 - val_accuracy: 0.5825\n","Epoch 14/100\n","375/375 [==============================] - ETA: 0s - loss: 2.2200 - accuracy: 0.4554\n","Epoch 14: val_loss improved from 1.50542 to 1.49176, saving model to model_checkpoints/checkpoint.ckpt\n","375/375 [==============================] - 63s 168ms/step - loss: 2.2200 - accuracy: 0.4554 - val_loss: 1.4918 - val_accuracy: 0.6002\n","Epoch 15/100\n","375/375 [==============================] - ETA: 0s - loss: 2.2305 - accuracy: 0.4529\n","Epoch 15: val_loss did not improve from 1.49176\n","375/375 [==============================] - 64s 170ms/step - loss: 2.2305 - accuracy: 0.4529 - val_loss: 1.5279 - val_accuracy: 0.5973\n","Epoch 16/100\n","375/375 [==============================] - ETA: 0s - loss: 2.2025 - accuracy: 0.4647\n","Epoch 16: val_loss did not improve from 1.49176\n","375/375 [==============================] - 64s 171ms/step - loss: 2.2025 - accuracy: 0.4647 - val_loss: 1.5671 - val_accuracy: 0.5879\n","Epoch 17/100\n","375/375 [==============================] - ETA: 0s - loss: 2.2152 - accuracy: 0.4616\n","Epoch 17: val_loss did not improve from 1.49176\n","375/375 [==============================] - 64s 170ms/step - loss: 2.2152 - accuracy: 0.4616 - val_loss: 1.4943 - val_accuracy: 0.6008\n","Epoch 18/100\n","375/375 [==============================] - ETA: 0s - loss: 2.1761 - accuracy: 0.4733\n","Epoch 18: val_loss did not improve from 1.49176\n","375/375 [==============================] - 62s 166ms/step - loss: 2.1761 - accuracy: 0.4733 - val_loss: 1.5502 - val_accuracy: 0.5949\n","Epoch 19/100\n","375/375 [==============================] - ETA: 0s - loss: 2.1318 - accuracy: 0.4801Restoring model weights from the end of the best epoch: 14.\n","\n","Epoch 19: val_loss did not improve from 1.49176\n","375/375 [==============================] - 63s 169ms/step - loss: 2.1318 - accuracy: 0.4801 - val_loss: 1.5312 - val_accuracy: 0.5973\n","Epoch 19: early stopping\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7fb200340310>"]},"metadata":{},"execution_count":97}],"source":["model.fit(train_data,\n","          validation_data=test_data,\n","          validation_steps=int(0.2*len(test_data)),\n","          epochs=100,\n","          callbacks=[early_stopping_callback,\n","                     checkpoint_callback],\n","          verbose=1)"],"metadata":{"pycharm":{"name":"#%%\n","is_executing":true},"id":"V1bGDxt30R08","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1666631755806,"user_tz":-180,"elapsed":1349586,"user":{"displayName":"V Lohmanova","userId":"03171650844612985685"}},"outputId":"e122a7a2-5308-4d47-8629-fea77364208f"}},{"cell_type":"code","source":["model.evaluate(test_data) # Not the best practice, validation dataset should be used here"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RnsKZC2D4pJ7","executionInfo":{"status":"ok","timestamp":1666631841223,"user_tz":-180,"elapsed":27569,"user":{"displayName":"V Lohmanova","userId":"03171650844612985685"}},"outputId":"86a1a269-f51f-49b4-9aeb-f8bdac06d639"},"execution_count":100,"outputs":[{"output_type":"stream","name":"stdout","text":["269/269 [==============================] - 27s 102ms/step - loss: 1.5423 - accuracy: 0.5885\n"]},{"output_type":"execute_result","data":{"text/plain":["[1.5422791242599487, 0.5884615182876587]"]},"metadata":{},"execution_count":100}]},{"cell_type":"markdown","source":["[Different models with Stanfor Dogs Dataset](https://paperswithcode.com/dataset/stanford-dogs)"],"metadata":{"id":"aCpVKyN5FWGS"}},{"cell_type":"markdown","source":["## How we can improve our model?\n","- Get more data\n","- Try different architecture (more complex or simpler)\n","- Train for Longer\n","\n","So if you want reach good results - experiment, experiment, experiment!\n","Good luck!"],"metadata":{"id":"Xn6jt2E3_xZQ"}},{"cell_type":"markdown","source":["## More model examples:"],"metadata":{"id":"N-n6GmwZGbEl"}},{"cell_type":"markdown","source":["One more example of Computer Vision classifier can be found [here](https://github.com/fulcrum101/MIPT_project_improved/blob/main/model.ipynb) with 99.27% accuracy, [AlexNet](https://paperswithcode.com/method/alexnet) ([Convolutional Neural Network (CNN)](https://paperswithcode.com/methods/category/convolutional-neural-networks)).\n","\n","Creating image `tf.data.Dataset` from folders with images can be found there as well. [More information.](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator)"],"metadata":{"id":"oeg3GvTYGedz"}}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":2},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython2","version":"2.7.6"},"colab":{"provenance":[{"file_id":"https://github.com/fulcrum101/Problemcon_hackathon_TensorFlow/blob/master/docs/part_2.ipynb","timestamp":1666628861871}]},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}